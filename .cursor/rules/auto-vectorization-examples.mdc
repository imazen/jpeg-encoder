---
description: *.rs, for making loops fast
globs: 
alwaysApply: false
---
# Using multiversion crate (this attribute can't be in a hot path since it decides at runtime using is_x86_feature_detected etc)
#[multiversion(targets("x86_64/x86-64-v2", ""x86_64+avx+avx2", "aarch64+neon"))]
fn square(x: &mut [f32]) {
    for v in x {
        *v *= *v;
    }
}


NOTE: these drop data since they don't use into_remainder.
#[inline(always)]
fn generic_slide_hash_chain<const N: usize>(table: &mut [u16], wsize: u16) {
    for chunk in table.chunks_exact_mut(N) {
        for m in chunk.iter_mut() {
            *m = m.saturating_sub(wsize);
        }
    }
}

fn slide_hash_chain_fallback(table: &mut [u16], wsize: u16) {
    // 32 means that 4 128-bit values can be processed per iteration. 
    // That appear to be the optimal amount on x86_64 (SSE) and aarch64 (NEON).
    generic_slide_hash_chain::<32>(table, wsize);
}

#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "avx2")]
unsafe fn slide_hash_chain_avx2(table: &mut [u16], wsize: u16) {
    // 64 means that 4 256-bit values can be processed per iteration.
    // That appear to be the optimal amount for avx2.
    generic_slide_hash_chain::<64>(table, wsize);
}

pub fn slide_hash_chain(table: &mut [u16], wsize: u16) {
    #[cfg(target_arch = "x86_64")]
    if core::is_x86_feature_detected!("avx2") {
        // SAFETY: the avx2 feature is available on the current CPU
        return unsafe { slide_hash_chain_avx2(table, wsize) };
    } 

    slide_hash_chain_fallback(table, wsize)
}